---
title: "Homework Week 1"
author: "Brian Ritz"
date: "Friday, January 16, 2015"
output: html_document
---

Use the data from the file `Week1_Homework_Project_Data.csv` to estimate linear model with `lm()`. Analize `summary()` of the estimated linear model.

What can you tell about the data and the fit?

By using any variables returned by `lm()` or `summary(lm.fit)` calculate the following characteristics of `glm()` that you would obtain if applied `glm()` to the same data.

You use glm() to check your answers, but, please, do not use glm object or any functions applied to glm object to calculate your results.

```{r}
Linear.Model.Data <- read.csv(file="Week1_Homework_Project_Data.csv",header=TRUE,sep=",")
head(Linear.Model.Data)
```


Estimate the model with `lm()`:
```{r}
Linear.Model.Data.lm<-lm(Output~Input1+Input2+Input3,data=Linear.Model.Data)
summary(Linear.Model.Data.lm)
```


Now we estimate using `glm()` so we can check:
```{r}
Returned.from.glm<-glm(Output~Input1+Input2+Input3,family=gaussian(link="identity"),data=Linear.Model.Data)
names(Returned.from.glm)
```


**1. Coefficients**

Coefficients will be the same even though lm() estimates using partial least squares and glm() estimates using maximum likelihood. This is because when we find the maximum of the log-likelihood function:

`-(n/2)* ln(2*pi*variance) * (1/(-2*variance)) * summation((yi - mu)^2)`

by varying mu, mu will equal the mean of all of the yi's. When we maximize that function by varying the variance, we get (1/n)*(summation(y-ybar)^2).

The coefficients for `glm()`:
```{r}
coefficients(Linear.Model.Data.lm)
```


**2. Residuals**

Residuals for `lm()` will be the same as `glm()`. This is because the glm and lm() models will have the same coefficients, therefore they will give the same estimates, therefore they will give the same residuals.

Check finding the residuals from both:
```{r}
matplot(1:length(Linear.Model.Data[,1]),cbind(Linear.Model.Data.lm$residuals,Returned.from.glm$residuals),type="l",ylab="Residuals",xlab="Count")
```

What is the difference between the two lines?
Are any of the differences above a trivial small amount (due to how the computer stores decimals)?
```{r}
any(abs(Linear.Model.Data.lm$residuals-Returned.from.glm$residuals)>.00000000001)
```
NOPE!


**3. Fitted Values**
Since we've already seen that the coefficients are the same, it would follow that the fitted values are the same as well because we are fitting the same data using the same coefficients.

```{r}
all.equal(fitted.values(Linear.Model.Data.lm), fitted.values(Returned.from.glm))
```
We have assered that the two vectors are equal.


**4. Linear Predicators**
Again, because we have proven that the coefficients are the same, they will provied the same predicitons when applied to the same data as long as the link function is the identity function, which it is in this case. We check tha the linear predictors vectors are equal below:

```{r}
all.equal(Linear.Model.Data.lm$fitted.values, Returned.from.glm$linear.predictors)
```

The linear.predictors property of the `glm` object will not always be equal to the fitted values of the `lm()` or even the fitted values of the `glm()`, because the link function will not always be the identiy function.


**5. Deviance**
We will check that the deviance for the `glm()` is equal to the sum of squared errors of the linear model. We will first do this using deviance() and then manually calculating deviance using the definitions in the lecture.

```{r}
# use deviance()
linear.model.sse <- sum(Linear.Model.Data.lm$residuals^2)
all.equal(linear.model.sse, deviance(Returned.from.glm))
```

Now, I calculate deviance manually in the function `calc.deviance()`, and then use that function to again assert that the deviance is equal to the lm sse. The function from the lecture is Summation((yI - fittedvalueI)^2) over all ys and fitted I's -- you will notice that this is the same formual as the SSE.
```{r}
# use manual calculation of deviance


# we need a gaussian log likelihood function -- after we estimate, we can find the log likelihood function only from the residuals
LL.Normal <- function(residuals){
  n<-length(residuals)
  sigma.sq <- sd(residuals)^2
  #sigma.sq <- mean(residuals^2)
  term.1 <- -(n/2)* log(2*pi*sigma.sq)
  term.2 <- -(1/(2*sigma.sq))*(sum((residuals)^2))
  
  LL <- term.1 + term.2
  return(LL)
}

calc.deviance<- function(glmfit){
  
  # the estaimation of variance of the Normal distribution underlying the sample is the same as the variance of the residuals
  
  # even for the saturated model, we can still estimate the variance of the y's with the residuals of the errors of the glm -- with the saturate model we estimate perfectly the ys, so the sd of the residuals will be zero, but, the sd of the estimates in that case will equal the sd of the residuals in the non-saturated case
  
  sigma.sq <- var(glmfit$residuals)
  n <- length(glmfit$residuals)

  # the saturated models residuals are all zeros, so we can simlify the log-likelihood function to the following:
  saturated <- -(n/2) * log(2*pi*sigma.sq)
  
  estimated <- LL.Normal(glmfit$residuals)
  dev <- 2*sigma.sq*(saturated - estimated)
  return(dev)
}

all.equal(linear.model.sse, calc.deviance(Linear.Model.Data.lm))
all.equal(linear.model.sse, calc.deviance(Returned.from.glm))
```
Very small difference, essentially they are equal.


**6. Akaike Information Criterion**
We will calculate the aic both using the `AIC()` function and manually using the formula from the lecture.

```{r}
all.equal(AIC(Linear.Model.Data.lm), AIC(Returned.from.glm))
```
The AIC from both are equal, using the `AIC()` function. Now I will calucluate the AIC manually and use that to compare to the Linear model aic.

```{r}
calc.AIC<- function(fit){
  # find the p -- number of paramters
  p<-length(fit$coefficients)
  
  aic <- -2 * LL.Normal(fit$residuals) + (2*p)

  return(aic)
}

all.equal(AIC(Returned.from.glm), calc.AIC(Linear.Model.Data.lm))
```
They are not equal, but they are close...I haven't found out why yet-could be that there are a few different formulas for AIC:
[linked phrase](http://www.researchgate.net/post/What_is_the_AIC_formula)


**7. Y**

The models were estimated on the same data, so the whys will be the same
```{r}
all.equal(Returned.from.glm$y, Linear.Model.Data[,1], check.attributes = FALSE)
```


**8. Null Deviance**

Null deviance is the deviance of the null model, when p = 1. So we will feed into our deviance function the residuals of when we compare the Ys to Ybar -- vector of (Yi-Ybar)


```{r}
# first we fit a null model
null.model <- lm(Output~1, data=Linear.Model.Data)
calc.deviance(null.model)
Returned.from.glm$null.deviance
all.equal(calc.deviance(null.model), Returned.from.glm$null.deviance)
```

**9. Dispersion**

```{r}
summary(Returned.from.glm)
sum(Linear.Model.Data.lm$residuals^2) / Linear.Model.Data.lm$df.residual
```
The dispersion is roughly equal to the square of residual standard error.
The two dispersions are equal -- we can see the glm dispersion in the summary, and the dispersion calculated from the linear model residuals below it.
